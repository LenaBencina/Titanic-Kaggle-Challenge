---
title: "Titanic survival prediction"
author: "Lena Bencina"
date: "12.1.2019"
output: html_document
---

<!-- include = FALSE prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks. -->
<!-- echo = FALSE prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures. -->
<!-- message = FALSE prevents messages that are generated by code from appearing in the finished file. -->
<!-- warning = FALSE prevents warnings that are generated by code from appearing in the finished. -->
<!-- fig.cap = "..." adds a caption to graphical results. -->

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = '../')
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```

```{r, include = FALSE}
# import all the code
source('Rscripts/AdditionalFunctions.R')
source('Rscripts/Preprocessing.R')
source('Rscripts/ImputeAge.R')
source('Rscripts/Train.R')
source('Rscripts/PreprocessingTestData.R')
source('Rscripts/Predict.R')
library(knitr)
library(kableExtra)
require(gridExtra)
```
<br>

## Importing data
We start by importing the training dataset. 
```{r, echo = FALSE, results = 'asis'}
kable(train.data.original[1:5,]) %>%  kable_styling(bootstrap_options = "striped", full_width = F)
```

We can see that our dataset has `r nrow(train.data.original)` observations and `r ncol(train.data.original)` features, from which Survived is a dependent feature and PassengerId is a unique feature used for "identification" of passengers.

We are dealing with categorical and numerical features, so we need to take care the **type conversion**. Features *`r factor.cols.train`* will be converted to factors and the rest will be left as it is.

```{r, echo = FALSE, results = 'asis'}
kable(train.data.original %>% summarise_all(class)) %>%  kable_styling(bootstrap_options = "striped", full_width = F)
```

Next, we need to check the **missing data**. let's compute the % of missing data and visualize it.

```{r, echo = FALSE}
kable(round(sort(sapply(train.data.original, function(x){sum(is.na(x))}))/n.train*100, 1), col.names = c('% of missing data')) %>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

```{r, echo = FALSE, warning = FALSE}
missmap(train.data.original, main = 'Missing values in train data', legend = FALSE, col = c('#81C853', '#275176'))
```

Three features have some missing data:

1. **CABIN**: It doesn't make sense to impute the data where there is only 23% values. We will remove the Cabin feature due to high amount of missing data.

2. **EMBARKED**: We don't have this information for only two passengers. We will remove these two observations for now and not waste time with imputations here. If there will be time we will get back to it and impute it with knn or some other classification algorithm.

3. **AGE**: Intuitive guess would be that age is an important feature for survival prediction. We will make an imputation model to predict the missing age, but first let's analyse all the features.

<br>
<br>

## Feature analysis

Check the overall distribution of dependent variable:
```{r, echo = FALSE}
kable(table(train.data.original$Survived), col.names = c('Survived', 'Freq'))%>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

There is enough observations in each classes, so we do not need to worry about that. Next, we will analyse each feature seperately.

<br>
<br>

### 1.NAME

Name is a text feature and thus it is not useful for further analysis in this form. One way to use it would be with additional text mining analysis, however, following intuition, a passenger's name is not really relevant for predicting the survival. On the other hand, we can see that each name includes the name title, such as Mrs., Ms., Miss, etc. We will extract it and make an additional feature (Name.title) from it. 

This is the distribution of original name titles:

```{r, echo = FALSE}
kable(rev(sort(table(name.title.original))), col.names = c('Original name title', 'Freq'))%>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

A lot of categories includes only one observation which can lead to poor predictions. let's try to combine it with the following mapping.

```{r, echo = FALSE}
kable(title.conv, col.names = c('Mapped to'))%>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

The distribution is now the following.

```{r, echo = FALSE}
kable(rev(sort(table(train.data$Name.title))), col.names = c('New name title', 'Freq'))%>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

The distribution of new feature by survival is presented in the next plot.

```{r, echo = FALSE}
plot.survival.dist.name.title
```

<br>
<br>

### 2. SEX

Next feature is Sex. Let's see the distribution by survival.

```{r, echo = FALSE}
plot.survival.dist.sex
```

It seems like Sex is correlated with survival (more women survived and more men died).

<br>
<br>

### 3. PCLASS

Pclass feature represents the ticket class of a passenger, i.e. a proxy for socio-economic status, which can be 1, 2, or 3. We can include it as ordered factor or as an integer. Because an integer will incorporate the distance between classes, we will include it as an integer.

Distribution of Pclass feature by survival is the following.

```{r, echo = FALSE}
plot.survival.dist.pclass
```

Pclass also looks correlated with survival. In the 1st class more people survived and in the 3rd class more people died.

<br>
<br>

### 4. TICKET

Ticket feature has `r ticket.classes.length` clasees. Most of them includes only one or two observations. The following table represents the number of classes with *n* observations.

```{r, echo = FALSE}
kable(table(table(train.data.original$Ticket)), col.names = c('x (Number of observations per class)', 'Number of classes with x observations')) %>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

We can see that 547 tickets are unique, which is more than half of the passengers. This information doesn't seem rrelevant. From this we can assume that new ticket classes will appear within the test set. For now we will delete the feature and later on we can try to parse some information such as ticket prefix from it and create a new feature.

<br>
<br>

### 5. FARE

Distribution of numerical feature Fare is distributed by survival as following.

```{r, echo = FALSE, warning = FALSE}
plot.fare.by.survived
```

We can see that survived had higher fares. For example, between people with fares less than (or equal) 50 number of died is aprox. two times the number of survived and vice versa for people with fares higher than 50.

```{r, echo = FALSE}
kable(fare.matrix.50) %>%  kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

<br>
<br>

### 6. EMBARKED

Embarked feature tells us the passenger's port of embarkation. 

```{r, echo = FALSE, warning = FALSE}
plot.survival.dist.embarked
```

Is this info relevant? Let's leave it for now and let the algorithms decide.

<br>
<br>

### 7. SIBSP & PARCH

A bit less intuitive features are features Sibsp and Parch, where SibSp is the number of siblings/spouses aboard and Parch is the number of parents/children aboard. These features are not so intuitive. Maybe we can find a better way to represent this information. We will create a new feature named Family.size using the following equation.

$$Family.size = Sibsp + Parch + 1$$


Another information which could be even more relevant is if the passenger was traveling alone, i.e. where family size is 0.

```{r, echo = FALSE}
plot.survival.dist.travel.alone
```

More people traveling alone died than survived.

<br>
<br>

## Age imputation

Now that we preprocessed all the features we can start dealing with imputation of missing Age values. Let's provide some useful information about the feature.

```{r, echo = FALSE}
age.tmp = data.frame(Missing = nrow(train.data.missing.age), Known = nrow(train.data.known.age))
rownames(age.tmp) = 'Number of observations'
kable(age.tmp) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

We will use linear regression for age prediction. After a few tries (as seen in the script ImputeAge.R) we obtain a model with all the predictors statistically significant.

```{r, echo = FALSE}
options(scipen = 99999)
summary(lm.model3)
```

We can compare the observed values with the predicted in the following plot.

```{r, echo = FALSE}
age.imputation.accuracy.plot
```

There are deviations for sure, but overall the fit is not so bad. It is not the best model but lets just try to proceed with survival prediction and get back to this later if there will be time.

The last thing to check is the distribution.

```{r, echo = FALSE}
grid.arrange(age.dist.plot, age.dist.imputed.plot, ncol=2)
```

The overall distribution before vs. after imputation is relatively similar with the exception of the middle peak around *age = 30*. We should analyse this further when trying to improve the survival prediction model.

<br>
<br>

## Preprocessing test data

Test data is being preprocessed in the same way as the train data. However, there were some differences needed to take into account. One of the problems that arrived was an additional feature with missing values.

```{r, echo = FALSE, warning = FALSE}
missmap(test.data.original, main = 'Missing values in test data', legend=FALSE, col = c('#81C853', '#275176'))
```

There is one observation without Fare information. For the sake of simplicity, we will impute it with an average Fare value. 

Age were imputed with the same model as in the train data.

And now, we can finally start with training.

<br>
<br>

## Model training 

We will use **CARET** library for training and prediction. As we are dealing with classification problem we will use five different algorithms suitable for classification. To avoid overfitting we will include a bootstrapping method, more specifically 10 cross-validation with 3 repeats. For consistency, all the models will use the same bootstrapping settings.

<br>
<br>

### 1. LOGISTIC REGRESSION

Starting with inclusion of all features towards reaching statistical significant predictors we finish with the following model. We are dealing with non parametric method, so we don't need to tune any parameters, thus choosing the final prediction formula is pretty much all we can do.

Formula used in the final regression model: $Survived ~ Sex + Pclass + Age + Family.size + Travel.alone$.

```{r, echo = FALSE}
summary(model.lr.3)
```

<br>
<br>

### 2. DECISION TREES

This algorithm has multiple parameters:
1. The complexity parameter (cp), which is the minimum improvement in the model needed at each node. It’s based on the cost complexity of the model.
2. Maxdeepth, which is used to set the maximum depth of a tree.
3. Minsplit, which is the minimum number of samples that must exist in a node for a split to happen or be attempted.
4. Minbucket, which is the minimum number of samples that can be present in a Terminal node.

Leaving *minsplit = 20*  and *minbucket = 7* as default values, we first tune *cp* with random values (output not included). In the second model (output below), we tune *maxdepth* parameter.

```{r, echo = FALSE}
model.dt.2
```

The second model reached the highest accuracy with *maxdepth = 4* and *cp = 0.01*, which was higher than accuracy at any value of *cp* in the first model. 

<br>
<br>

### 3. RANDOM FOREST

```{r, echo = FALSE}
model.rf.1
```

<br>
<br>

### 4. K-NEAREST NEIGHBOURS (KNN)

The only parameter to tune here is the number of nearest neighbours (*k*). We fit the model with values of *k* between 1 and 15.

```{r, echo = FALSE}
model.knn
```

The model reached the highest accuracy with *k = 7*, however as expected the training accuracy is very low comparing to the others.

<br>
<br>

### 5. SUPPORT VECTOR MACHINE (SVM)


```{r, echo = FALSE}
model.svm.2
```

<br>
<br>

## Model comparison

We will compare the models using two different measures.

<br>

### Accuracy

First, we will compare the accuracy across all fitted models.

```{r, echo = FALSE}
summary(results, metric = 'Accuracy')
```

```{r, echo = FALSE}
bwplot(results, metric = 'Accuracy')
```

We can see that Random Forest's performance scored the highest (average) training  accuracy, which was not that much higher than the (average) training accuracy of SVM.
<br>

### ROC (Receiver operating curve)

An additional, a bit less intuitive measure is the AUC measure  (area under the receiver operating curve).

```{r, echo = FALSE}
roc.plot
```

```{r, echo = FALSE}
kable(AUC)  %>% kable_styling(bootstrap_options = "striped", full_width = F, position = 'center')
```

## Prediction

Using random forest model with *mtry* parameter set to 5 and *ntree* to 500 we predict the survival of passengers in the test data.

After submitting the predictions to Kaggle we get the final (test) accuracy 78%.

We could improve the predictions with:

* Deeper feature analysis, such as create new features or remove some of the included.
* Further analysis of Age imputation models.
* Extending parameter's tunning (for example using different kernels with SVM algorithm).
* Choosing different versions of specific algotihms or including additional ones, such as Neural Networks or Naive Bayes.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


















